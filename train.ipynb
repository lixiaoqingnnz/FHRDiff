{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc959df",
   "metadata": {},
   "source": [
    "# train conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cffe5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os \n",
    "import yaml\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "import dataset\n",
    "from model import DiffWave\n",
    "from params import params\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def read_yaml(yaml_path):\n",
    "    with open(yaml_path, 'r') as file:\n",
    "        yaml_data = yaml.safe_load(file)\n",
    "        \n",
    "    return yaml_data\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config_info = read_yaml('config.yaml')\n",
    "\n",
    "model_dir = config_info['model_dir']\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "dataset_dir = config_info['signal_dir']\n",
    "spectrogram_dir = config_info['spectrogram_dir']\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=os.path.join(model_dir, 'training.log'), level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "batch_size = config_info['batch_size']\n",
    "epoches = config_info['epoches']\n",
    "\n",
    "\n",
    "#noise_schedule = config_info['noise_schedule']\n",
    "noise_schedule = np.linspace(1e-4, 0.05, 50).tolist()\n",
    "beta = np.array(noise_schedule)\n",
    "noise_level = np.cumprod(1 - beta)\n",
    "noise_level = torch.tensor(noise_level.astype(np.float32))\n",
    "loss_fn = nn.L1Loss()\n",
    "summary_writer = None\n",
    "\n",
    "trainDataset = dataset.ctg_dataset(dataset_dir, spectrogram_dir)\n",
    "train_loader = DataLoader(\n",
    "    dataset=trainDataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True)\n",
    "\n",
    "learning_rate = config_info['learning_rate']\n",
    "model = DiffWave(params).to(device)\n",
    "\n",
    "# lr = config_info['learning_rate']\n",
    "\n",
    "if config_info['optimizer'] == 'torch.optim.AdamW':\n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n",
    "    \n",
    "def train_unconditional(noise_level):\n",
    "    shutil.copy('config.yaml', os.path.join(model_dir, 'config.yaml'))\n",
    "    shutil.copy('params.py', os.path.join(model_dir, 'params.py'))\n",
    "    for epoch in range(epoches):\n",
    "        train_loss = []\n",
    "        best_loss = float('inf')\n",
    "        for step, (signal, spectrogram) in enumerate(train_loader):\n",
    "            signal = signal.to(device)\n",
    "            spectrogram = spectrogram.to(device)\n",
    "            model.train()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            N, T = signal.shape\n",
    "            noise_level = noise_level.to(device)\n",
    "            \n",
    "            \n",
    "            # 要查一下为什么是从1e-4到0.05\n",
    "            # 明天对一下公式\n",
    "            t = torch.randint(0, len(noise_schedule), [N], device=signal.device)\n",
    "            noise_scale = noise_level[t].unsqueeze(1)\n",
    "            noise_scale_sqrt = noise_scale**0.5\n",
    "            noise = torch.randn_like(signal)\n",
    "            noisy_signal = noise_scale_sqrt * signal + (1.0 - noise_scale)**0.5 * noise\n",
    "            \n",
    "\n",
    "            \n",
    "            # spetrogram是原来model的contain，后面需要修改\n",
    "            predicted = model(noisy_signal, t, spectrogram=spectrogram)\n",
    "            loss = loss_fn(noise, predicted.squeeze(1))\n",
    "            \n",
    "            logging.info(f'Batch {step}/{len(train_loader)} loss : {loss}')\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # 假设train_loss是一个包含PyTorch张量的列表\n",
    "        train_loss = [item.detach().numpy() for item in train_loss]  \n",
    "        train_loss = np.array(train_loss, dtype=np.float32)  \n",
    "        #if train_loss.mean() <= best_loss:\n",
    "         #   best_loss = train_loss.mean()\n",
    "          #  torch.save(diffusion.state_dict(), 'runs/best_model.pth')\n",
    "        if (epoch+1) % 2 == 0:\n",
    "            savename = str(epoch+1) + '.pth'\n",
    "            savename = os.path.join(model_dir, savename)\n",
    "            torch.save(model.state_dict(), savename)\n",
    "\n",
    "\n",
    "        logging.info(f'Epoch {epoch}/{epoches} loss : {train_loss.mean()}')\n",
    "\n",
    "\n",
    "train_unconditional(noise_level)\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc739a",
   "metadata": {},
   "source": [
    "# train unconditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bd878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unconditional(noise_level):\n",
    "    shutil.copy('config.yaml', os.path.join(model_dir, 'config.yaml'))\n",
    "    shutil.copy('params.py', os.path.join(model_dir, 'params.py'))\n",
    "    for epoch in range(epoches):\n",
    "        train_loss = []\n",
    "        best_loss = float('inf')\n",
    "        for step, signal in enumerate(train_loader):\n",
    "            signal = signal.to(device)\n",
    "            model.train()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            N, T = signal.shape\n",
    "            noise_level = noise_level.to(device)\n",
    "            \n",
    "            \n",
    "            # 要查一下为什么是从1e-4到0.05\n",
    "            # 明天对一下公式\n",
    "            t = torch.randint(0, len(noise_schedule), [N], device=signal.device)\n",
    "            noise_scale = noise_level[t].unsqueeze(1)\n",
    "            noise_scale_sqrt = noise_scale**0.5\n",
    "            noise = torch.randn_like(signal)\n",
    "            noisy_signal = noise_scale_sqrt * signal + (1.0 - noise_scale)**0.5 * noise\n",
    "            \n",
    "\n",
    "            \n",
    "            # spetrogram是原来model的contain，后面需要修改\n",
    "            predicted = model(noisy_signal, t, spectrogram=None)\n",
    "            loss = loss_fn(noise, predicted.squeeze(1))\n",
    "            \n",
    "            logging.info(f'Batch {step}/{len(train_loader)} loss : {loss}')\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # 假设train_loss是一个包含PyTorch张量的列表\n",
    "        train_loss = [item.detach().numpy() for item in train_loss]  \n",
    "        train_loss = np.array(train_loss, dtype=np.float32)  \n",
    "        #if train_loss.mean() <= best_loss:\n",
    "         #   best_loss = train_loss.mean()\n",
    "          #  torch.save(diffusion.state_dict(), 'runs/best_model.pth')\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            savename = str(epoch+1) + '.pth'\n",
    "            savename = os.path.join(model_dir, savename)\n",
    "            torch.save(model.state_dict(), savename)\n",
    "\n",
    "\n",
    "        logging.info(f'Epoch {epoch}/{epoches} loss : {train_loss.mean()}')\n",
    "\n",
    "\n",
    "train(noise_level)\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27163623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
